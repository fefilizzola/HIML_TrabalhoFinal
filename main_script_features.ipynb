{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import getcwd, remove, listdir\n",
    "from os.path import join \n",
    "import matplotlib.pyplot as plt\n",
    "from lvm_read import read\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from statsmodels.tsa.ar_model import AutoReg,ar_select_order\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import (train_test_split, RepeatedKFold,\n",
    "RandomizedSearchCV)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string=\"white_noise_\"+str(1)+\".lvm\"\n",
    "d=read(join(getcwd(),f'Case_R_(+25)/Case_R_(+25)_1/',string))\n",
    "d[0]['Channel names'].pop()\n",
    "df=pd.DataFrame(d[0]['data'],columns=d[0]['Channel names'])         \n",
    "sel = ar_select_order(df[\"Ch2\"],30)\n",
    "sel.ar_lags\n",
    "res = sel.model.fit()\n",
    "\n",
    "fig = plt.figure(facecolor='White',figsize=(16, 9))\n",
    "fig = res.plot_diagnostics(fig=fig, lags=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params Download Data.\n",
    "case_scheme = [\"R\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\"]\n",
    "CH_numbers = 8\n",
    "na = 17\n",
    "df_AR = []\n",
    "for jj, case in enumerate(tqdm(case_scheme,desc='Importing Data')):\n",
    "    [remove(join(getcwd(),f'Case_{case}_(+25)/Case_{case}_(+25)_1/',x)) for x in listdir(join(getcwd(),f'Case_{case}_(+25)/Case_{case}_(+25)_1/')) if '.pkl' in x]\n",
    "    [remove(join(getcwd(),f'Case_{case}_(+25)/Case_{case}_(+25)_2/',x)) for x in listdir(join(getcwd(),f'Case_{case}_(+25)/Case_{case}_(+25)_2/')) if '.pkl' in x]\n",
    "    for i in range(1, 41):\n",
    "        if i > 20:\n",
    "            ij = i-20\n",
    "            sensor_scheme = \"2\"\n",
    "        else:\n",
    "            ij=i\n",
    "            sensor_scheme =\"1\" # Sensor Scheme Choosed\n",
    "\n",
    "        string=\"white_noise_\"+str(ij)+\".lvm\"\n",
    "        try:\n",
    "            d=read(join(getcwd(),f'Case_{case}_(+25)/Case_{case}_(+25)_{sensor_scheme}/',string))\n",
    "            d[0]['Channel names'].pop()\n",
    "            df=pd.DataFrame(d[0]['data'],columns=d[0]['Channel names'])         \n",
    "            ARmodel1 = AutoReg(df[f\"Ch1\"],na).fit()\n",
    "            ARmodel2 = AutoReg(df[f\"Ch2\"],na).fit()\n",
    "            ARmodel3 = AutoReg(df[f\"Ch3\"],na).fit()\n",
    "            ARmodel4 = AutoReg(df[f\"Ch4\"],na).fit()\n",
    "            ARmodel5 = AutoReg(df[f\"Ch5\"],na).fit()\n",
    "            ARmodel6 = AutoReg(df[f\"Ch6\"],na).fit()\n",
    "            ARmodel7 = AutoReg(df[f\"Ch7\"],na).fit()\n",
    "            ARmodel8 = AutoReg(df[f\"Ch8\"],na).fit()\n",
    "            ARparams=np.concatenate([ARmodel1.params,ARmodel2.params,ARmodel3.params,ARmodel4.params,\n",
    "                                     ARmodel5.params,ARmodel6.params,ARmodel7.params,ARmodel8.params,[jj+1]])\n",
    "            df_AR.append(ARparams)\n",
    "        except:\n",
    "            continue\n",
    "df_AR=np.array(df_AR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA().fit(df_AR[:,:-1])\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "plt.figure(facecolor='White')\n",
    "fig, ax = plt.subplots()\n",
    "exp_var = pca.explained_variance_ratio_\n",
    "yi = np.cumsum(exp_var)\n",
    "xi = np.arange(1, len(exp_var)+1, step=1)\n",
    "\n",
    "plt.ylim(0.0,1.1)\n",
    "plt.plot(xi, yi, linestyle='--', color='b')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.xticks(np.arange(0,len(exp_var)+1, step=1)) #change from 0-based array index to 1-based human-readable label\n",
    "plt.ylabel('Cumulative variance (%)')\n",
    "plt.title('The number of components needed to explain variance')\n",
    "\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=14)\n",
    "plt.axhline(y=0.99, color='g', linestyle='-')\n",
    "plt.text(0.5, 0.95, '99% cut-off threshold', color = 'green', fontsize=14)\n",
    "plt.axhline(y=0.80, color='black', linestyle='-')\n",
    "plt.text(0.5, 0.75, '80% cut-off threshold', color = 'black', fontsize=14)\n",
    "\n",
    "ax.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = pd.DataFrame({'target':df_AR[:,-1]})\n",
    "df_all_PCA = pd.DataFrame(PCA(n_components=5).fit_transform(df_AR[:,:-1]))#,columns=[f'{x} Component' for x in range(1,np.size(yi)+1)])\n",
    "df_parallel = pd.concat([df_all_PCA,y_all],axis=1)\n",
    "temp = [str(x) for x in df_parallel['target']]\n",
    "df_parallel['target'] = temp\n",
    "plt.figure(facecolor='White')\n",
    "fig = pd.plotting.parallel_coordinates(StandardScaler(df_parallel),\"target\") # px.parallel_coordinates(df_parallel,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df_parallel.melt(id_vars=['target'])\n",
    "sns.boxplot(data = df_melted[df_melted['variable']<=10],x='variable',y='value',hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4=sns.pairplot(df_parallel,hue='target',height=2)\n",
    "fig4._legend.remove()\n",
    "handles = fig4._legend_data.values()\n",
    "labels = case_scheme\n",
    "fig4.fig.legend(handles=handles, labels=labels, loc='lower center', ncol=3,title='Categorias')\n",
    "fig4.fig.subplots_adjust(top=0.95, bottom=0.15)\n",
    "fig4.fig.suptitle('Dataset transformado por PCA e classificado pelo Label conhecido',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TSNE = pd.DataFrame(TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(df_parallel[df_parallel.columns[0:2]]))\n",
    "df_TSNE = pd.concat([df_TSNE,df_parallel['target']],axis=1)\n",
    "fig5=sns.pairplot(df_TSNE,hue='target',height=4)\n",
    "fig5._legend.remove()\n",
    "handles = fig5._legend_data.values()\n",
    "labels = case_scheme\n",
    "fig5.fig.legend(handles=handles, labels=labels, loc='lower center', ncol=3,title='Categorias')\n",
    "fig5.fig.subplots_adjust(top=0.9, bottom=0.2)\n",
    "fig5.fig.suptitle('Dataset transformado por T-SNE e classificado pelo Label conhecido',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append((\"LRG\",LogisticRegression()))\n",
    "models.append((\"SVC\",SVC()))\n",
    "models.append((\"KNN\",KNeighborsClassifier()))\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids =[]\n",
    "param_grids.append( #Softmax\n",
    "    \n",
    "        {\n",
    "            \"LRG__C\":[1, 10, 20, 60, 70, 100],\n",
    "            \"LRG__solver\" :[ 'lbfgs', 'liblinear', 'sag'],\n",
    "            \"LRG__multi_class\":['multinomial']  \n",
    "        }\n",
    "    \n",
    ")\n",
    "param_grids.append( #SVC\n",
    "    \n",
    "        {\n",
    "            \"SVC__C\"      : stats.loguniform(1e-1,1e3),\n",
    "            \"SVC__kernel\" : ['linear','poly','rbf','sigmoid'],\n",
    "            \"SVC__degree\" : stats.randint(2,5),\n",
    "            \"SVC__gamma\"  : stats.loguniform(1e-4,1e0),\n",
    "            #\"SVC__epsilon\"  : stats.loguniform(1e-4,1e1)\n",
    "        }\n",
    "    \n",
    ")\n",
    "param_grids.append( #KNN\n",
    "    \n",
    "        {\n",
    "            \"KNN__n_neighbors\" : stats.randint(2,100),\n",
    "            \"KNN__weights\"      : [\"uniform\",\"distance\"],\n",
    "            \"KNN__algorithm\" : [ \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "            \"KNN__leaf_size\" : stats.randint(1,30)            \n",
    "        }\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = 5\n",
    "nkiter = 50\n",
    "n_iter = 100\n",
    "acc=[]\n",
    "cfmx =[]\n",
    "best_params =[]\n",
    "acc_all=[]\n",
    "cfmx_all =[]\n",
    "best_params_all =[]\n",
    "for jj in tqdm(range(0,100),desc='Simulação Monte Carlo'):\n",
    "    for i,md in enumerate(models):\n",
    "        #print(f'Iteração {i+1} - {md}\\n')\n",
    "        #Separar Data set em conjuntos de treino e teste ()\n",
    "        trainx, testx, trainy, testy = train_test_split(df_AR[:,:-1], df_AR[:,-1], test_size=0.3, random_state=jj)\n",
    "        trainx = PCA(n_components=5).fit_transform(trainx)\n",
    "        testex = PCA(n_components=5).transform(testex)            \n",
    "\n",
    "        rkf = RepeatedKFold(n_splits=kfolds,n_repeats=nkiter,random_state=jj)\n",
    "\n",
    "        clf = Pipeline([(\"scaler\",StandardScaler()),(md)])\n",
    "\n",
    "        param_grid = param_grids[i]\n",
    "\n",
    "        #Cria modelo\n",
    "        rnd_model = RandomizedSearchCV(clf,verbose=0,n_iter=n_iter,n_jobs=6,cv=rkf,\n",
    "                                        random_state=jj,param_distributions=param_grid,scoring=accuracy_score)\n",
    "        rnd_model.fit(trainx,trainy)\n",
    "        best_params.append(rnd_model.best_params_)\n",
    "        yh_teste = rnd_model.predict(testy)\n",
    "        acc.append(accuracy_score(testy, yh_teste,normalize=True))\n",
    "        cfmx.append(confusion_matrix(testy, yh_teste))\n",
    "        # print(f'Resultados: Acurácia={acc[i]}')\n",
    "        # print(f'Beste Params: {best_params[i]}\\n')\n",
    "    acc_all.append(acc)\n",
    "    cfmx_all.append(cfmx)\n",
    "    best_params_all.append(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='White',figsize=(30, 5), dpi=80)\n",
    "plt.subplot(131)\n",
    "group_counts_x1 = [\"{0:0.0f}\".format(value) for value in\n",
    "                cfmx[0].flatten()]            \n",
    "group_percentages_x1 = [\"{0:.2%}\".format(value) for value in\n",
    "                     cfmx[0].flatten()/np.sum(cfmx[0])]                 \n",
    "labels_x1 = [f\"{v2}\" for v2, v3 in\n",
    "          zip(group_counts_x1,group_percentages_x1)]\n",
    "labels_x1 = np.asarray(labels_x1).reshape(cfmx[0].shape)\n",
    "ax1 = sns.heatmap(cfmx[0]/len(df_parallel['target']), annot=labels_x1,  cmap='Blues', fmt='')\n",
    "ax1.set_title(f'Softmax - Matriz Confusão -\\n Acurácia:{round(100*acc[0],2)}%')\n",
    "ax1.set_xlabel('\\nValores Estimados')\n",
    "ax1.set_ylabel('Valores Reais')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax1.xaxis.set_ticklabels(case_scheme)\n",
    "ax1.yaxis.set_ticklabels(case_scheme)\n",
    "\n",
    "plt.subplot(132)\n",
    "group_counts_x2 = [\"{0:0.0f}\".format(value) for value in\n",
    "                cfmx[1].flatten()]            \n",
    "group_percentages_x2 = [\"{0:.2%}\".format(value) for value in\n",
    "                     cfmx[1].flatten()/np.sum(cfmx[1])]                 \n",
    "labels_x2 = [f\"{v2}\" for v2, v3 in\n",
    "          zip(group_counts_x2,group_percentages_x2)]\n",
    "labels_x2 = np.asarray(labels_x2).reshape(cfmx[1].shape)\n",
    "ax2 = sns.heatmap(cfmx[1]/len(df_parallel['target']), annot=labels_x2,  cmap='Blues', fmt='')\n",
    "ax2.set_title(f'SVM - Matriz Confusão -\\n Acurácia:{round(100*acc[1],2)}%')\n",
    "ax2.set_xlabel('\\nValores Estimados')\n",
    "ax2.set_ylabel('Valores Reais')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax2.xaxis.set_ticklabels(case_scheme)\n",
    "ax2.yaxis.set_ticklabels(case_scheme)\n",
    "\n",
    "plt.subplot(133)\n",
    "group_counts_x3 = [\"{0:0.0f}\".format(value) for value in\n",
    "                cfmx[2].flatten()]            \n",
    "group_percentages_x3 = [\"{0:.2%}\".format(value) for value in\n",
    "                     cfmx[2].flatten()/np.sum(cfmx[2])]                 \n",
    "labels_x3 = [f\"{v2}\" for v2, v3 in\n",
    "          zip(group_counts_x3,group_percentages_x3)]\n",
    "labels_x3 = np.asarray(labels_x3).reshape(cfmx[2].shape)\n",
    "ax3 = sns.heatmap(cfmx[2]/len(df_parallel['target']), annot=labels_x3,  cmap='Blues', fmt='')\n",
    "ax3.set_title(f'kNN - Matriz Confusão -\\n Acurácia:{round(100*acc[2],2)}%')\n",
    "ax3.set_xlabel('\\nValores Estimados')\n",
    "ax3.set_ylabel('Valores Reais')\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax3.xaxis.set_ticklabels(case_scheme)\n",
    "ax3.yaxis.set_ticklabels(case_scheme)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
